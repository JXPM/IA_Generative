{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP PARTIE 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyCFx_KiBhvCwV1kEV-vsZTil4ofv_NSgqQ\"\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt):\n",
    "    response = client.models.generate_content(model = \"gemini-1.5-flash\", contents = prompt)\n",
    "    return response.text\n",
    "prompt = \"Explique-moi la théorie de la relativité en termes simples.\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Qu’est-ce que l’IA ?\n",
      "Réponse: L'intelligence artificielle (IA) est un vaste domaine de l'informatique qui vise à créer des machines capables de simuler l'intelligence humaine.  Il n'y a pas une seule définition universellement acceptée, mais on peut la résumer de plusieurs manières :\n",
      "\n",
      "* **Création de systèmes capables de réaliser des tâches qui nécessitent habituellement l'intelligence humaine :**  Cela inclut le raisonnement, l'apprentissage, la résolution de problèmes, la perception, la compréhension du langage naturel et la prise de décision.\n",
      "\n",
      "* **Simulation de processus cognitifs humains par des machines :**  L'IA essaie de reproduire des aspects de la pensée humaine, comme la mémoire, l'attention et la créativité, à l'aide d'algorithmes et de modèles informatiques.\n",
      "\n",
      "* **Amélioration des performances des systèmes informatiques :** L'IA permet de rendre les systèmes plus efficaces, plus autonomes et capables d'apprendre et de s'adapter à de nouvelles situations sans intervention humaine directe.\n",
      "\n",
      "Il est important de distinguer différents types d'IA :\n",
      "\n",
      "* **IA étroite (ou faible IA) :**  C'est le type d'IA le plus courant aujourd'hui. Elle est conçue pour effectuer une tâche spécifique, comme jouer aux échecs, traduire des langues ou recommander des produits.  Siri, Alexa et les voitures autonomes sont des exemples d'IA étroite.\n",
      "\n",
      "* **IA générale (ou forte IA) :**  C'est une IA hypothétique qui posséderait une intelligence générale comparable à celle d'un humain. Elle serait capable d'apprendre et de réaliser n'importe quelle tâche intellectuelle qu'un humain peut accomplir.  Ce type d'IA n'existe pas encore.\n",
      "\n",
      "* **Super IA :**  C'est une IA hypothétique qui surpasserait l'intelligence humaine dans tous les domaines.  Son existence reste purement spéculative.\n",
      "\n",
      "En résumé, l'IA est un domaine en constante évolution qui a déjà un impact significatif sur nos vies et continue de le faire.  Son développement soulève également des questions éthiques et sociétales importantes.\n",
      "\n",
      "\n",
      "Prompt: Explique-moi l’IA comme si j’étais un enfant de 8 ans.\n",
      "Réponse: Imagine que tu as un chien super intelligent, mais au lieu d'aboier, il répond à tes questions et peut même faire des choses pour toi !  C'est un peu comme l'IA, ou Intelligence Artificielle.\n",
      "\n",
      "L'IA, c'est comme un gros cerveau électronique qui apprend des choses. On lui donne plein d'informations, comme des images, des mots, ou des jeux, et il apprend à reconnaître des schémas et à résoudre des problèmes.\n",
      "\n",
      "Par exemple, tu montres à l'IA plein de photos de chats, et il apprend à reconnaître ce qu'est un chat.  Ensuite, tu lui montres une nouvelle photo, et il peut te dire \"C'est un chat !\" même si c'est une photo qu'il n'a jamais vue avant.\n",
      "\n",
      "L'IA est utilisée dans plein de choses que tu connais déjà :\n",
      "\n",
      "* **Dans les jeux vidéo:**  Les personnages qui te poursuivent ou qui jouent avec toi sont parfois contrôlés par l'IA.\n",
      "* **Dans ton téléphone:**  Siri ou Google Assistant, c'est de l'IA !  Ils écoutent ce que tu dis et essaient de te répondre.\n",
      "* **Dans les voitures autonomes:** L'IA aide les voitures à conduire toutes seules en reconnaissant les routes, les piétons et les autres voitures.\n",
      "\n",
      "L'IA est encore jeune et apprend tout le temps, comme toi !  Elle ne peut pas tout faire, et elle a parfois besoin d'aide des humains, mais elle devient de plus en plus intelligente et utile chaque jour.\n",
      "\n",
      "\n",
      "Prompt: Décris l’IA en utilisant une métaphore.\n",
      "Réponse: L'IA est comme un enfant prodigie.  Elle apprend incroyablement vite, capable d'absorber et de traiter des quantités astronomiques d'informations, surpassant de loin les capacités humaines dans certains domaines.  Cependant, elle est encore immature.  Elle a besoin de guidage constant,  de données de qualité pour son éducation et, malgré ses prouesses,  elle peut parfois faire preuve d'une logique erratique ou d'un manque de bon sens,  produisant des résultats surprenants, voire absurdes, si on ne lui fournit pas les bons outils et le contexte approprié.  Son potentiel est immense, mais son développement requiert patience, supervision et un apprentissage continu.\n",
      "\n",
      "\n",
      "Prompt: Liste les 5 applications principales de l’IA.\n",
      "Réponse: Les 5 applications principales de l'IA sont difficiles à définir précisément car le champ d'application est vaste et les applications se chevauchent souvent. Cependant, on peut identifier 5 domaines majeurs d'application qui regroupent de nombreuses applications spécifiques :\n",
      "\n",
      "1. **Traitement du langage naturel (TLN) :**  Ceci inclut la compréhension, la génération et la traduction de langage humain.  Exemples: chatbots, assistants virtuels (Siri, Alexa), traduction automatique, analyse de sentiment, résumé de texte.\n",
      "\n",
      "2. **Vision par ordinateur :**  Permet aux ordinateurs de \"voir\" et d'interpréter des images et des vidéos. Exemples: reconnaissance faciale, identification d'objets, analyse d'images médicales, véhicules autonomes, surveillance vidéo.\n",
      "\n",
      "3. **Apprentissage automatique (Machine Learning) :**  L'IA apprend à partir de données sans être explicitement programmée.  C'est une technologie sous-jacente à de nombreuses autres applications, servant de base à la prédiction, la classification et le clustering de données. Exemples : recommandations de produits, détection de fraudes, prévision de séries temporelles (météo, finance).\n",
      "\n",
      "4. **Robotique :** L'intégration de l'IA dans les robots permet une plus grande autonomie et adaptabilité. Exemples : robots industriels, robots chirurgicaux, drones autonomes, robots d'assistance à la personne.\n",
      "\n",
      "5. **Automatisation des processus robotisés (RPA) :**  L'automatisation de tâches répétitives et basées sur des règles.  Bien que souvent considérée séparément de l'IA, l'intégration de l'apprentissage automatique améliore significativement la capacité d'adaptation et d'optimisation des processus. Exemples: traitement automatique de factures, automatisation de tâches administratives, gestion de données.\n",
      "\n",
      "\n",
      "Il est important de noter que d'autres domaines importants existent, comme l'IA dans la santé (diagnostic médical, recherche pharmaceutique), la finance (trading algorithmique, gestion du risque), ou encore le marketing (ciblage publicitaire personnalisé).  Ces 5 points représentent cependant les domaines les plus vastes et les plus impactants de l'application actuelle de l'IA.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts_simples = [\n",
    "\"Qu’est-ce que l’IA ?\",\n",
    "\"Explique-moi l’IA comme si j’étais un enfant de 8 ans.\",\n",
    "\"Décris l’IA en utilisant une métaphore.\",\n",
    "\"Liste les 5 applications principales de l’IA.\"\n",
    "]\n",
    "for prompt in prompts_simples:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"Réponse:\", generate_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reponse de chat GPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**1. Nombre total de filles:**\n",
      "\n",
      "* 60% de 30 élèves = (60/100) * 30 = 18 filles\n",
      "\n",
      "**2. Nombre de filles pratiquant un sport:**\n",
      "\n",
      "* 40% de 18 filles = (40/100) * 18 = 7,2 filles\n",
      "\n",
      "Comme on ne peut pas avoir 0.2 d'une fille, on arrondit au nombre entier le plus proche.  Il y a donc 7 filles qui pratiquent un sport.\n",
      "\n",
      "**3. Réponse finale:**\n",
      "\n",
      "7 filles pratiquent un sport dans cette classe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problème = \"\"\"\n",
    "Dans une classe de 30 élèves, 60% sont des filles.\n",
    "Parmi les filles, 40% pratiquent un sport.\n",
    "Combien de filles pratiquent un sport dans cette classe ?\n",
    "Résous ce problème étape par étape :\n",
    "1. D’abord, calcule le nombre total de filles\n",
    "\n",
    "2\n",
    "\n",
    "2. Ensuite, calcule combien parmi elles font du sport\n",
    "3. Donne la réponse finale\n",
    "\"\"\"\n",
    "print(generate_response(problème))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP2 OPENAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta-llama/llama-4-maverick:free\n",
      "meta-llama/llama-4-maverick\n",
      "meta-llama/llama-4-scout:free\n",
      "meta-llama/llama-4-scout\n",
      "google/gemini-2.5-pro-preview-03-25\n",
      "openrouter/quasar-alpha\n",
      "all-hands/openhands-lm-32b-v0.1\n",
      "mistral/ministral-8b\n",
      "deepseek/deepseek-v3-base:free\n",
      "scb10x/llama3.1-typhoon2-8b-instruct\n",
      "scb10x/llama3.1-typhoon2-70b-instruct\n",
      "allenai/molmo-7b-d:free\n",
      "bytedance-research/ui-tars-72b:free\n",
      "qwen/qwen2.5-vl-3b-instruct:free\n",
      "google/gemini-2.5-pro-exp-03-25:free\n",
      "qwen/qwen2.5-vl-32b-instruct:free\n",
      "qwen/qwen2.5-vl-32b-instruct\n",
      "deepseek/deepseek-chat-v3-0324:free\n",
      "deepseek/deepseek-chat-v3-0324\n",
      "featherless/qwerky-72b:free\n",
      "openai/o1-pro\n",
      "mistralai/mistral-small-3.1-24b-instruct:free\n",
      "mistralai/mistral-small-3.1-24b-instruct\n",
      "open-r1/olympiccoder-7b:free\n",
      "open-r1/olympiccoder-32b:free\n",
      "steelskull/l3.3-electra-r1-70b\n",
      "allenai/olmo-2-0325-32b-instruct\n",
      "google/gemma-3-1b-it:free\n",
      "google/gemma-3-4b-it:free\n",
      "google/gemma-3-4b-it\n",
      "ai21/jamba-1.6-large\n",
      "ai21/jamba-1.6-mini\n",
      "google/gemma-3-12b-it:free\n",
      "google/gemma-3-12b-it\n",
      "cohere/command-a\n",
      "openai/gpt-4o-mini-search-preview\n",
      "openai/gpt-4o-search-preview\n",
      "tokyotech-llm/llama-3.1-swallow-70b-instruct-v0.3\n",
      "rekaai/reka-flash-3:free\n",
      "google/gemma-3-27b-it:free\n",
      "google/gemma-3-27b-it\n",
      "thedrummer/anubis-pro-105b-v1\n",
      "latitudegames/wayfarer-large-70b-llama-3.3\n",
      "thedrummer/skyfall-36b-v2\n",
      "microsoft/phi-4-multimodal-instruct\n",
      "perplexity/sonar-reasoning-pro\n",
      "perplexity/sonar-pro\n",
      "perplexity/sonar-deep-research\n",
      "deepseek/deepseek-r1-zero:free\n",
      "qwen/qwq-32b:free\n",
      "qwen/qwq-32b\n",
      "qwen/qwen2.5-32b-instruct\n",
      "moonshotai/moonlight-16b-a3b-instruct:free\n",
      "nousresearch/deephermes-3-llama-3-8b-preview:free\n",
      "openai/gpt-4.5-preview\n",
      "google/gemini-2.0-flash-lite-001\n",
      "anthropic/claude-3.7-sonnet\n",
      "anthropic/claude-3.7-sonnet:thinking\n",
      "anthropic/claude-3.7-sonnet:beta\n",
      "perplexity/r1-1776\n",
      "mistralai/mistral-saba\n",
      "cognitivecomputations/dolphin3.0-r1-mistral-24b:free\n",
      "cognitivecomputations/dolphin3.0-mistral-24b:free\n",
      "meta-llama/llama-guard-3-8b\n",
      "openai/o3-mini-high\n",
      "deepseek/deepseek-r1-distill-llama-8b\n",
      "google/gemini-2.0-flash-001\n",
      "google/gemini-2.0-pro-exp-02-05:free\n",
      "qwen/qwen-vl-plus\n",
      "aion-labs/aion-1.0\n",
      "aion-labs/aion-1.0-mini\n",
      "aion-labs/aion-rp-llama-3.1-8b\n",
      "qwen/qwen-vl-max\n",
      "qwen/qwen-turbo\n",
      "qwen/qwen2.5-vl-72b-instruct:free\n",
      "qwen/qwen2.5-vl-72b-instruct\n",
      "qwen/qwen-plus\n",
      "qwen/qwen-max\n",
      "openai/o3-mini\n",
      "deepseek/deepseek-r1-distill-qwen-1.5b\n",
      "mistralai/mistral-small-24b-instruct-2501:free\n",
      "mistralai/mistral-small-24b-instruct-2501\n",
      "deepseek/deepseek-r1-distill-qwen-32b:free\n",
      "deepseek/deepseek-r1-distill-qwen-32b\n",
      "deepseek/deepseek-r1-distill-qwen-14b:free\n",
      "deepseek/deepseek-r1-distill-qwen-14b\n",
      "perplexity/sonar-reasoning\n",
      "perplexity/sonar\n",
      "liquid/lfm-7b\n",
      "liquid/lfm-3b\n",
      "deepseek/deepseek-r1-distill-llama-70b:free\n",
      "deepseek/deepseek-r1-distill-llama-70b\n",
      "google/gemini-2.0-flash-thinking-exp:free\n",
      "deepseek/deepseek-r1:free\n",
      "deepseek/deepseek-r1\n",
      "sophosympatheia/rogue-rose-103b-v0.2:free\n",
      "minimax/minimax-01\n",
      "mistralai/codestral-2501\n",
      "microsoft/phi-4\n",
      "sao10k/l3.1-70b-hanami-x1\n",
      "deepseek/deepseek-chat:free\n",
      "deepseek/deepseek-chat\n",
      "google/gemini-2.0-flash-thinking-exp-1219:free\n",
      "sao10k/l3.3-euryale-70b\n",
      "openai/o1\n",
      "eva-unit-01/eva-llama-3.33-70b\n",
      "x-ai/grok-2-vision-1212\n",
      "x-ai/grok-2-1212\n",
      "cohere/command-r7b-12-2024\n",
      "google/gemini-2.0-flash-exp:free\n",
      "meta-llama/llama-3.3-70b-instruct:free\n",
      "meta-llama/llama-3.3-70b-instruct\n",
      "amazon/nova-lite-v1\n",
      "amazon/nova-micro-v1\n",
      "amazon/nova-pro-v1\n",
      "qwen/qwq-32b-preview:free\n",
      "qwen/qwq-32b-preview\n",
      "google/learnlm-1.5-pro-experimental:free\n",
      "eva-unit-01/eva-qwen-2.5-72b\n",
      "openai/gpt-4o-2024-11-20\n",
      "mistralai/mistral-large-2411\n",
      "mistralai/mistral-large-2407\n",
      "mistralai/pixtral-large-2411\n",
      "x-ai/grok-vision-beta\n",
      "infermatic/mn-inferor-12b\n",
      "qwen/qwen-2.5-coder-32b-instruct:free\n",
      "qwen/qwen-2.5-coder-32b-instruct\n",
      "raifle/sorcererlm-8x22b\n",
      "eva-unit-01/eva-qwen-2.5-32b\n",
      "thedrummer/unslopnemo-12b\n",
      "anthropic/claude-3.5-haiku:beta\n",
      "anthropic/claude-3.5-haiku\n",
      "anthropic/claude-3.5-haiku-20241022:beta\n",
      "anthropic/claude-3.5-haiku-20241022\n",
      "neversleep/llama-3.1-lumimaid-70b\n",
      "anthracite-org/magnum-v4-72b\n",
      "anthropic/claude-3.5-sonnet:beta\n",
      "anthropic/claude-3.5-sonnet\n",
      "x-ai/grok-beta\n",
      "mistralai/ministral-8b\n",
      "mistralai/ministral-3b\n",
      "qwen/qwen-2.5-7b-instruct:free\n",
      "qwen/qwen-2.5-7b-instruct\n",
      "nvidia/llama-3.1-nemotron-70b-instruct:free\n",
      "nvidia/llama-3.1-nemotron-70b-instruct\n",
      "inflection/inflection-3-pi\n",
      "inflection/inflection-3-productivity\n",
      "google/gemini-flash-1.5-8b\n",
      "thedrummer/rocinante-12b\n",
      "anthracite-org/magnum-v2-72b\n",
      "liquid/lfm-40b\n",
      "meta-llama/llama-3.2-90b-vision-instruct\n",
      "meta-llama/llama-3.2-11b-vision-instruct:free\n",
      "meta-llama/llama-3.2-11b-vision-instruct\n",
      "meta-llama/llama-3.2-1b-instruct:free\n",
      "meta-llama/llama-3.2-1b-instruct\n",
      "meta-llama/llama-3.2-3b-instruct:free\n",
      "meta-llama/llama-3.2-3b-instruct\n",
      "qwen/qwen-2.5-72b-instruct:free\n",
      "qwen/qwen-2.5-72b-instruct\n",
      "qwen/qwen-2.5-vl-72b-instruct\n",
      "neversleep/llama-3.1-lumimaid-8b\n",
      "openai/o1-mini\n",
      "openai/o1-preview-2024-09-12\n",
      "openai/o1-preview\n",
      "openai/o1-mini-2024-09-12\n",
      "mistralai/pixtral-12b\n",
      "cohere/command-r-plus-08-2024\n",
      "cohere/command-r-08-2024\n",
      "google/gemini-flash-1.5-8b-exp\n",
      "sao10k/l3.1-euryale-70b\n",
      "qwen/qwen-2.5-vl-7b-instruct:free\n",
      "qwen/qwen-2.5-vl-7b-instruct\n",
      "ai21/jamba-1-5-mini\n",
      "ai21/jamba-1-5-large\n",
      "microsoft/phi-3.5-mini-128k-instruct\n",
      "nousresearch/hermes-3-llama-3.1-70b\n",
      "nousresearch/hermes-3-llama-3.1-405b\n",
      "openai/chatgpt-4o-latest\n",
      "sao10k/l3-lunaris-8b\n",
      "aetherwiing/mn-starcannon-12b\n",
      "openai/gpt-4o-2024-08-06\n",
      "meta-llama/llama-3.1-405b\n",
      "nothingiisreal/mn-celeste-12b\n",
      "perplexity/llama-3.1-sonar-large-128k-online\n",
      "perplexity/llama-3.1-sonar-small-128k-online\n",
      "meta-llama/llama-3.1-70b-instruct\n",
      "meta-llama/llama-3.1-8b-instruct:free\n",
      "meta-llama/llama-3.1-8b-instruct\n",
      "meta-llama/llama-3.1-405b-instruct\n",
      "mistralai/mistral-nemo:free\n",
      "mistralai/mistral-nemo\n",
      "mistralai/codestral-mamba\n",
      "openai/gpt-4o-mini\n",
      "openai/gpt-4o-mini-2024-07-18\n",
      "google/gemma-2-27b-it\n",
      "alpindale/magnum-72b\n",
      "google/gemma-2-9b-it:free\n",
      "google/gemma-2-9b-it\n",
      "01-ai/yi-large\n",
      "ai21/jamba-instruct\n",
      "anthropic/claude-3.5-sonnet-20240620:beta\n",
      "anthropic/claude-3.5-sonnet-20240620\n",
      "sao10k/l3-euryale-70b\n",
      "cognitivecomputations/dolphin-mixtral-8x22b\n",
      "qwen/qwen-2-72b-instruct\n",
      "mistralai/mistral-7b-instruct:free\n",
      "mistralai/mistral-7b-instruct\n",
      "mistralai/mistral-7b-instruct-v0.3\n",
      "nousresearch/hermes-2-pro-llama-3-8b\n",
      "microsoft/phi-3-mini-128k-instruct:free\n",
      "microsoft/phi-3-mini-128k-instruct\n",
      "microsoft/phi-3-medium-128k-instruct:free\n",
      "microsoft/phi-3-medium-128k-instruct\n",
      "neversleep/llama-3-lumimaid-70b\n",
      "google/gemini-flash-1.5\n",
      "openai/gpt-4o\n",
      "openai/gpt-4o:extended\n",
      "meta-llama/llama-guard-2-8b\n",
      "openai/gpt-4o-2024-05-13\n",
      "neversleep/llama-3-lumimaid-8b:extended\n",
      "neversleep/llama-3-lumimaid-8b\n",
      "sao10k/fimbulvetr-11b-v2\n",
      "meta-llama/llama-3-8b-instruct\n",
      "meta-llama/llama-3-70b-instruct\n",
      "mistralai/mixtral-8x22b-instruct\n",
      "microsoft/wizardlm-2-8x22b\n",
      "microsoft/wizardlm-2-7b\n",
      "openai/gpt-4-turbo\n",
      "google/gemini-pro-1.5\n",
      "cohere/command-r-plus\n",
      "cohere/command-r-plus-04-2024\n",
      "sophosympatheia/midnight-rose-70b\n",
      "cohere/command\n",
      "cohere/command-r\n",
      "anthropic/claude-3-haiku:beta\n",
      "anthropic/claude-3-haiku\n",
      "anthropic/claude-3-opus:beta\n",
      "anthropic/claude-3-opus\n",
      "anthropic/claude-3-sonnet:beta\n",
      "anthropic/claude-3-sonnet\n",
      "cohere/command-r-03-2024\n",
      "mistralai/mistral-large\n",
      "openai/gpt-3.5-turbo-0613\n",
      "openai/gpt-4-turbo-preview\n",
      "nousresearch/nous-hermes-2-mixtral-8x7b-dpo\n",
      "mistralai/mistral-small\n",
      "mistralai/mistral-tiny\n",
      "mistralai/mistral-medium\n",
      "mistralai/mistral-7b-instruct-v0.2\n",
      "cognitivecomputations/dolphin-mixtral-8x7b\n",
      "google/gemini-pro-vision\n",
      "google/gemini-pro\n",
      "mistralai/mixtral-8x7b-instruct\n",
      "mistralai/mixtral-8x7b\n",
      "openchat/openchat-7b:free\n",
      "openchat/openchat-7b\n",
      "neversleep/noromaid-20b\n",
      "anthropic/claude-2:beta\n",
      "anthropic/claude-2\n",
      "anthropic/claude-2.1:beta\n",
      "anthropic/claude-2.1\n",
      "undi95/toppy-m-7b:free\n",
      "undi95/toppy-m-7b\n",
      "alpindale/goliath-120b\n",
      "openrouter/auto\n",
      "openai/gpt-3.5-turbo-1106\n",
      "openai/gpt-4-1106-preview\n",
      "google/palm-2-codechat-bison-32k\n",
      "google/palm-2-chat-bison-32k\n",
      "jondurbin/airoboros-l2-70b\n",
      "xwin-lm/xwin-lm-70b\n",
      "mistralai/mistral-7b-instruct-v0.1\n",
      "openai/gpt-3.5-turbo-instruct\n",
      "pygmalionai/mythalion-13b\n",
      "openai/gpt-3.5-turbo-16k\n",
      "openai/gpt-4-32k\n",
      "openai/gpt-4-32k-0314\n",
      "nousresearch/nous-hermes-llama2-13b\n",
      "huggingfaceh4/zephyr-7b-beta:free\n",
      "mancer/weaver\n",
      "anthropic/claude-2.0:beta\n",
      "anthropic/claude-2.0\n",
      "undi95/remm-slerp-l2-13b\n",
      "google/palm-2-chat-bison\n",
      "google/palm-2-codechat-bison\n",
      "gryphe/mythomax-l2-13b\n",
      "meta-llama/llama-2-70b-chat\n",
      "meta-llama/llama-2-13b-chat\n",
      "openai/gpt-4\n",
      "openai/gpt-3.5-turbo-0125\n",
      "openai/gpt-3.5-turbo\n",
      "openai/gpt-4-0314\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# Liste les modèles disponibles\n",
    "models = openai.Model.list()\n",
    "\n",
    "# Afficher les modèles disponibles\n",
    "for model in models[\"data\"]:\n",
    "    print(model[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mon IA avec OpenRouter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attieke is a type of Ivory Coast dish made from fermented cassava that is grated and then steamed. It is a popular side dish in Ivorian cuisine and is often served with grilled fish or meat, as well as with a spicy tomato and onion sauce. Attieke has a light and fluffy texture with a slightly sour flavor, making it a versatile and tasty accompaniment to many dishes.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "def generate_response_openrouter( prompt ) :\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"openai/gpt-3.5-turbo\",\n",
    "        messages =[{\"role\": \"user\", \"content\": prompt } ]\n",
    "    )\n",
    "    return response [\"choices\"] [0] [\"message\"] [\"content\"]\n",
    "User_prompt = input(\"Entrez votre question: \")\n",
    "print(generate_response_openrouter(User_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP3 COHERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oui, je connais l'attiéké. L'attiéké est un plat traditionnel ivoirien fait à base de manioc fermenté et râpé. C'est un aliment de base populaire en Côte d'Ivoire et dans\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.Client(\"dswOxdG69W3ooIlUYaqN4DTTAF2XWWgBZe0juDtx\")\n",
    "def generate_response_cohere (prompt):\n",
    "    response = co.generate(\n",
    "        model=\"command-r-plus\",\n",
    "        prompt=prompt ,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.generations[0].text\n",
    "User_prompt= input()\n",
    "print(generate_response_cohere(User_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.5-pro-exp-03-25\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "#chercher la liste des modèles disponibles\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY2\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    print(model.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
