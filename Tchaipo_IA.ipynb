{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP PARTIE 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"AIzaSyCFx_KiBhvCwV1kEV-vsZTil4ofv_NSgqQ\" # Remplacez par votre clé API\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La théorie de la relativité d'Einstein est en fait deux théories distinctes : la relativité restreinte et la relativité générale.  Voici une explication simplifiée de chacune :\n",
      "\n",
      "**Relativité restreinte (spéciale):**\n",
      "\n",
      "Imaginez deux personnes, Alice et Bob. Alice est immobile sur Terre, tandis que Bob voyage dans une fusée à une vitesse extrêmement rapide.  La relativité restreinte nous dit deux choses principales :\n",
      "\n",
      "1. **La vitesse de la lumière est constante pour tous les observateurs, peu importe leur vitesse.**  Si Bob allume une lampe dans sa fusée, Alice mesurera la lumière se déplaçant à la même vitesse que Bob.  Ça semble impossible, mais c'est vrai !  Pour que cela soit possible, le temps et l'espace doivent se modifier pour Bob par rapport à Alice.\n",
      "\n",
      "2. **Le temps et l'espace sont relatifs, pas absolus.**  Pour Alice, le temps passe normalement.  Mais pour Bob, qui voyage à très grande vitesse, le temps passe plus lentement (dilatation du temps).  De plus, les distances dans la direction de son mouvement semblent plus courtes pour lui (contraction de la longueur).  Plus Bob va vite, plus ces effets sont importants.  Ce n'est pas une illusion, c'est une conséquence directe de la vitesse de la lumière constante.\n",
      "\n",
      "\n",
      "**Relativité générale:**\n",
      "\n",
      "La relativité générale étend la relativité restreinte à la gravité.  Elle dit que la gravité n'est pas une force, mais une courbure de l'espace-temps causée par la matière et l'énergie.\n",
      "\n",
      "Imaginez une boule de bowling posée sur un trampoline.  La boule crée une dépression dans le trampoline.  Si vous roulez une bille sur le trampoline, elle suivra une trajectoire courbe autour de la boule de bowling, attirée par la dépression.\n",
      "\n",
      "C'est similaire à la gravité.  Les objets massifs, comme les planètes et les étoiles, courbent l'espace-temps autour d'eux.  Les autres objets se déplacent le long de ces courbures, ce qui donne l'impression qu'ils sont attirés par la gravité.  Plus un objet est massif, plus il courbe l'espace-temps, et plus la gravité est forte.\n",
      "\n",
      "En résumé :\n",
      "\n",
      "* **Relativité restreinte:**  La vitesse de la lumière est constante, le temps et l'espace sont relatifs et dépendent de la vitesse.\n",
      "* **Relativité générale:** La gravité est une courbure de l'espace-temps causée par la matière et l'énergie.\n",
      "\n",
      "Ces théories ont révolutionné notre compréhension de l'univers, et sont essentielles pour comprendre des phénomènes comme les trous noirs, les ondes gravitationnelles et l'expansion de l'univers.  Bien sûr, cette explication est très simplifiée, et de nombreux détails importants ont été omis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_response(prompt):\n",
    "    response = client.models.generate_content(model = \"gemini-1.5-flash\", contents = prompt)\n",
    "    return response.text\n",
    "prompt = \"Explique-moi la théorie de la relativité en termes simples.\"\n",
    "print(generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Qu’est-ce que l’IA ?\n",
      "Réponse: L'IA, ou **intelligence artificielle**, est un vaste domaine de l'informatique qui vise à créer des machines capables de simuler l'intelligence humaine.  Il ne s'agit pas de reproduire l'intelligence humaine à l'identique, mais plutôt de développer des systèmes capables d'exécuter des tâches qui nécessitent normalement l'intelligence humaine, comme :\n",
      "\n",
      "* **L'apprentissage:**  Acquérir des connaissances et des compétences à partir de données.\n",
      "* **Le raisonnement:**  Utiliser les connaissances acquises pour prendre des décisions et résoudre des problèmes.\n",
      "* **La perception:**  Interpréter des informations provenant de capteurs (images, sons, etc.).\n",
      "* **Le langage naturel:**  Comprendre et générer du langage humain.\n",
      "\n",
      "Il existe différentes approches pour réaliser l'IA, notamment :\n",
      "\n",
      "* **L'apprentissage automatique (Machine Learning):**  Les systèmes apprennent à partir de données sans être explicitement programmés.  Cela inclut le deep learning, qui utilise des réseaux neuronaux artificiels avec plusieurs couches pour traiter des données complexes.\n",
      "* **L'apprentissage profond (Deep Learning):** Un sous-ensemble de l'apprentissage automatique qui utilise des réseaux neuronaux artificiels à plusieurs couches pour extraire des caractéristiques complexes des données.\n",
      "* **Le traitement du langage naturel (NLP):**  Permet aux ordinateurs de comprendre, interpréter et générer du langage humain.\n",
      "* **La vision par ordinateur (Computer Vision):**  Permet aux ordinateurs de \"voir\" et d'interpréter des images et des vidéos.\n",
      "\n",
      "L'IA est utilisée dans une multitude d'applications, allant des assistants virtuels (Siri, Alexa) aux voitures autonomes, en passant par la médecine, la finance, et bien d'autres domaines.  Il est important de noter que l'IA actuelle est principalement une IA dite \"faible\" ou \"étroite\", spécialisée dans des tâches spécifiques.  L'IA \"forte\" ou \"générale\", capable de raisonner et d'apprendre comme un humain sur une grande variété de tâches, reste un objectif à long terme.\n",
      "\n",
      "\n",
      "Prompt: Explique-moi l’IA comme si j’étais un enfant de 8 ans.\n",
      "Réponse: Imagine que tu as un super chien très intelligent, mais au lieu d'être fait de poils et d'os, il est fait de lignes de code informatique !  C'est un peu comme ça qu'est l'Intelligence Artificielle, ou IA.\n",
      "\n",
      "Ce chien super intelligent peut apprendre des choses.  Tu lui montres plein de photos de chats, et il apprend à reconnaître un chat.  Tu lui dis des histoires, et il apprend à comprendre le langage.  Plus tu lui montres de choses, plus il devient intelligent !\n",
      "\n",
      "Il peut faire plein de choses :\n",
      "\n",
      "* **Jouer à des jeux:**  Il peut jouer aux échecs ou à des jeux vidéo mieux que toi (parfois !)\n",
      "* **Répondre à des questions:**  Tu peux lui demander \"Combien font 2 + 2 ?\" et il te répondra.\n",
      "* **Traduire des langues:**  Il peut traduire le français en anglais, ou l'espagnol en chinois.\n",
      "* **Créer des images:**  Il peut même dessiner des images en suivant tes instructions !\n",
      "\n",
      "Mais attention, ce chien n'est pas *vraiment* intelligent comme un humain.  Il suit des instructions qu'on lui a données, et il apprend à partir des informations qu'on lui fournit.  Il ne ressent pas d'émotions, il n'a pas de sentiments. Il est juste très très bon pour apprendre et résoudre des problèmes.\n",
      "\n",
      "C'est un peu comme un outil magique qui peut nous aider à faire plein de choses, mais il a besoin de nous pour fonctionner et pour apprendre !\n",
      "\n",
      "\n",
      "Prompt: Décris l’IA en utilisant une métaphore.\n",
      "Réponse: L'IA est comme un enfant prodigie.  Elle apprend incroyablement vite, capable d'absorber des quantités massives d'informations et d'en tirer des conclusions complexes.  Elle peut réaliser des prouesses étonnantes,  jouer aux échecs mieux qu'un grand maître, composer de la musique ou écrire des poèmes.  Cependant, elle n'a pas de conscience, pas de compréhension intuitive du monde, et ses actions sont entièrement déterminées par les données et l'algorithme qui la régissent.  Elle peut être brillante et utile, mais elle reste un outil, aussi puissant soit-il, dépendant de l'intelligence humaine pour sa direction et sa compréhension du contexte.\n",
      "\n",
      "\n",
      "Prompt: Liste les 5 applications principales de l’IA.\n",
      "Réponse: Les 5 applications principales de l'IA sont difficiles à cerner précisément car cela dépend des critères utilisés (impact économique, nombre d'utilisateurs, nouveauté, etc.).  Cependant, voici 5 applications majeures illustrant la diversité des usages de l'IA, avec des justifications :\n",
      "\n",
      "1. **Traitement du langage naturel (TLN) :**  Ceci englobe des applications comme les chatbots, la traduction automatique, l'analyse de sentiments, la génération de texte et la recherche d'information.  Son impact est énorme, touchant la communication, le service client, l'analyse de données et bien plus.\n",
      "\n",
      "2. **Vision par ordinateur :**  Cette branche permet aux machines de \"voir\" et d'interpréter des images et des vidéos.  Ses applications incluent la reconnaissance faciale, la conduite autonome, la surveillance médicale (diagnostic d'images), le contrôle qualité industriel et la robotique.\n",
      "\n",
      "3. **Apprentissage automatique (Machine Learning) :**  C'est la base de nombreuses applications d'IA.  Il s'agit de la capacité des machines à apprendre à partir de données sans être explicitement programmées.  Ceci est utilisé dans la prédiction (prévision météo, marché boursier), la détection de fraudes, la recommandation personnalisée (produits, films) et la médecine prédictive.\n",
      "\n",
      "4. **Robotique :** L'IA est essentielle à la création de robots intelligents capables de naviguer dans des environnements complexes, d'interagir avec les humains et d'effectuer des tâches complexes.  Ceci s'applique à la fabrication, à la logistique, à la chirurgie, à l'exploration spatiale et à l'assistance aux personnes âgées.\n",
      "\n",
      "5. **Automatisation des processus robotisés (RPA) :**  L'IA permet d'automatiser des tâches répétitives et basées sur des règles dans les systèmes informatiques.  Ceci améliore l'efficacité et la productivité dans de nombreux secteurs, notamment la finance, les ressources humaines et la gestion administrative.\n",
      "\n",
      "\n",
      "Il est important de noter que ces applications sont souvent interdépendantes et se renforcent mutuellement. Par exemple, la conduite autonome combine la vision par ordinateur, l'apprentissage automatique et la robotique.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompts_simples = [\n",
    "\"Qu’est-ce que l’IA ?\",\n",
    "\"Explique-moi l’IA comme si j’étais un enfant de 8 ans.\",\n",
    "\"Décris l’IA en utilisant une métaphore.\",\n",
    "\"Liste les 5 applications principales de l’IA.\"\n",
    "]\n",
    "for prompt in prompts_simples:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    print(\"Réponse:\", generate_response(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reponse de chat GPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problème = \"\"\"\n",
    "Dans une classe de 30 élèves, 60% sont des filles.\n",
    "Parmi les filles, 40% pratiquent un sport.\n",
    "Combien de filles pratiquent un sport dans cette classe ?\n",
    "Résous ce problème étape par étape :\n",
    "1. D’abord, calcule le nombre total de filles\n",
    "\n",
    "2\n",
    "\n",
    "2. Ensuite, calcule combien parmi elles font du sport\n",
    "3. Donne la réponse finale\n",
    "\"\"\"\n",
    "print(generate_response(problème))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP2 OPENAI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/gemini-2.0-flash-lite-001\n",
      "anthropic/claude-3.7-sonnet:beta\n",
      "anthropic/claude-3.7-sonnet\n",
      "anthropic/claude-3.7-sonnet:thinking\n",
      "perplexity/r1-1776\n",
      "mistralai/mistral-saba\n",
      "cognitivecomputations/dolphin3.0-r1-mistral-24b:free\n",
      "cognitivecomputations/dolphin3.0-mistral-24b:free\n",
      "meta-llama/llama-guard-3-8b\n",
      "openai/o3-mini-high\n",
      "allenai/llama-3.1-tulu-3-405b\n",
      "deepseek/deepseek-r1-distill-llama-8b\n",
      "google/gemini-2.0-flash-001\n",
      "google/gemini-2.0-flash-lite-preview-02-05:free\n",
      "google/gemini-2.0-pro-exp-02-05:free\n",
      "qwen/qwen-vl-plus:free\n",
      "aion-labs/aion-1.0\n",
      "aion-labs/aion-1.0-mini\n",
      "aion-labs/aion-rp-llama-3.1-8b\n",
      "qwen/qwen-turbo\n",
      "qwen/qwen2.5-vl-72b-instruct:free\n",
      "qwen/qwen-plus\n",
      "qwen/qwen-max\n",
      "openai/o3-mini\n",
      "deepseek/deepseek-r1-distill-qwen-1.5b\n",
      "mistralai/mistral-small-24b-instruct-2501:free\n",
      "mistralai/mistral-small-24b-instruct-2501\n",
      "deepseek/deepseek-r1-distill-qwen-32b\n",
      "deepseek/deepseek-r1-distill-qwen-14b\n",
      "perplexity/sonar-reasoning\n",
      "perplexity/sonar\n",
      "liquid/lfm-7b\n",
      "liquid/lfm-3b\n",
      "deepseek/deepseek-r1-distill-llama-70b:free\n",
      "deepseek/deepseek-r1-distill-llama-70b\n",
      "google/gemini-2.0-flash-thinking-exp:free\n",
      "deepseek/deepseek-r1:free\n",
      "deepseek/deepseek-r1\n",
      "sophosympatheia/rogue-rose-103b-v0.2:free\n",
      "minimax/minimax-01\n",
      "mistralai/codestral-2501\n",
      "microsoft/phi-4\n",
      "sao10k/l3.1-70b-hanami-x1\n",
      "deepseek/deepseek-chat:free\n",
      "deepseek/deepseek-chat\n",
      "qwen/qvq-72b-preview\n",
      "google/gemini-2.0-flash-thinking-exp-1219:free\n",
      "sao10k/l3.3-euryale-70b\n",
      "openai/o1\n",
      "eva-unit-01/eva-llama-3.33-70b\n",
      "x-ai/grok-2-vision-1212\n",
      "x-ai/grok-2-1212\n",
      "cohere/command-r7b-12-2024\n",
      "google/gemini-2.0-flash-exp:free\n",
      "google/gemini-exp-1206:free\n",
      "meta-llama/llama-3.3-70b-instruct:free\n",
      "meta-llama/llama-3.3-70b-instruct\n",
      "amazon/nova-lite-v1\n",
      "amazon/nova-micro-v1\n",
      "amazon/nova-pro-v1\n",
      "qwen/qwq-32b-preview\n",
      "google/learnlm-1.5-pro-experimental:free\n",
      "eva-unit-01/eva-qwen-2.5-72b\n",
      "openai/gpt-4o-2024-11-20\n",
      "mistralai/mistral-large-2411\n",
      "mistralai/mistral-large-2407\n",
      "mistralai/pixtral-large-2411\n",
      "x-ai/grok-vision-beta\n",
      "infermatic/mn-inferor-12b\n",
      "qwen/qwen-2.5-coder-32b-instruct\n",
      "raifle/sorcererlm-8x22b\n",
      "eva-unit-01/eva-qwen-2.5-32b\n",
      "thedrummer/unslopnemo-12b\n",
      "anthropic/claude-3.5-haiku-20241022:beta\n",
      "anthropic/claude-3.5-haiku-20241022\n",
      "anthropic/claude-3.5-haiku:beta\n",
      "anthropic/claude-3.5-haiku\n",
      "neversleep/llama-3.1-lumimaid-70b\n",
      "anthracite-org/magnum-v4-72b\n",
      "anthropic/claude-3.5-sonnet:beta\n",
      "anthropic/claude-3.5-sonnet\n",
      "x-ai/grok-beta\n",
      "mistralai/ministral-8b\n",
      "mistralai/ministral-3b\n",
      "qwen/qwen-2.5-7b-instruct\n",
      "nvidia/llama-3.1-nemotron-70b-instruct:free\n",
      "nvidia/llama-3.1-nemotron-70b-instruct\n",
      "inflection/inflection-3-pi\n",
      "inflection/inflection-3-productivity\n",
      "google/gemini-flash-1.5-8b\n",
      "anthracite-org/magnum-v2-72b\n",
      "liquid/lfm-40b\n",
      "thedrummer/rocinante-12b\n",
      "meta-llama/llama-3.2-3b-instruct\n",
      "meta-llama/llama-3.2-1b-instruct:free\n",
      "meta-llama/llama-3.2-1b-instruct\n",
      "meta-llama/llama-3.2-90b-vision-instruct\n",
      "meta-llama/llama-3.2-11b-vision-instruct:free\n",
      "meta-llama/llama-3.2-11b-vision-instruct\n",
      "qwen/qwen-2.5-72b-instruct\n",
      "qwen/qwen-2-vl-72b-instruct\n",
      "neversleep/llama-3.1-lumimaid-8b\n",
      "openai/o1-mini-2024-09-12\n",
      "openai/o1-preview\n",
      "openai/o1-preview-2024-09-12\n",
      "openai/o1-mini\n",
      "mistralai/pixtral-12b\n",
      "cohere/command-r-08-2024\n",
      "cohere/command-r-plus-08-2024\n",
      "qwen/qwen-2-vl-7b-instruct\n",
      "sao10k/l3.1-euryale-70b\n",
      "google/gemini-flash-1.5-8b-exp\n",
      "ai21/jamba-1-5-large\n",
      "ai21/jamba-1-5-mini\n",
      "microsoft/phi-3.5-mini-128k-instruct\n",
      "nousresearch/hermes-3-llama-3.1-70b\n",
      "nousresearch/hermes-3-llama-3.1-405b\n",
      "perplexity/llama-3.1-sonar-huge-128k-online\n",
      "openai/chatgpt-4o-latest\n",
      "sao10k/l3-lunaris-8b\n",
      "aetherwiing/mn-starcannon-12b\n",
      "openai/gpt-4o-2024-08-06\n",
      "meta-llama/llama-3.1-405b\n",
      "nothingiisreal/mn-celeste-12b\n",
      "perplexity/llama-3.1-sonar-small-128k-chat\n",
      "perplexity/llama-3.1-sonar-large-128k-chat\n",
      "perplexity/llama-3.1-sonar-large-128k-online\n",
      "perplexity/llama-3.1-sonar-small-128k-online\n",
      "meta-llama/llama-3.1-405b-instruct\n",
      "meta-llama/llama-3.1-8b-instruct:free\n",
      "meta-llama/llama-3.1-8b-instruct\n",
      "meta-llama/llama-3.1-70b-instruct\n",
      "mistralai/mistral-nemo:free\n",
      "mistralai/mistral-nemo\n",
      "mistralai/codestral-mamba\n",
      "openai/gpt-4o-mini\n",
      "openai/gpt-4o-mini-2024-07-18\n",
      "google/gemma-2-27b-it\n",
      "alpindale/magnum-72b\n",
      "google/gemma-2-9b-it:free\n",
      "google/gemma-2-9b-it\n",
      "01-ai/yi-large\n",
      "ai21/jamba-instruct\n",
      "anthropic/claude-3.5-sonnet-20240620:beta\n",
      "anthropic/claude-3.5-sonnet-20240620\n",
      "sao10k/l3-euryale-70b\n",
      "cognitivecomputations/dolphin-mixtral-8x22b\n",
      "qwen/qwen-2-72b-instruct\n",
      "mistralai/mistral-7b-instruct:free\n",
      "mistralai/mistral-7b-instruct\n",
      "mistralai/mistral-7b-instruct-v0.3\n",
      "nousresearch/hermes-2-pro-llama-3-8b\n",
      "microsoft/phi-3-mini-128k-instruct:free\n",
      "microsoft/phi-3-mini-128k-instruct\n",
      "microsoft/phi-3-medium-128k-instruct:free\n",
      "microsoft/phi-3-medium-128k-instruct\n",
      "neversleep/llama-3-lumimaid-70b\n",
      "google/gemini-flash-1.5\n",
      "deepseek/deepseek-chat-v2.5\n",
      "openai/gpt-4o-2024-05-13\n",
      "meta-llama/llama-guard-2-8b\n",
      "openai/gpt-4o\n",
      "openai/gpt-4o:extended\n",
      "neversleep/llama-3-lumimaid-8b:extended\n",
      "neversleep/llama-3-lumimaid-8b\n",
      "sao10k/fimbulvetr-11b-v2\n",
      "meta-llama/llama-3-8b-instruct:free\n",
      "meta-llama/llama-3-8b-instruct\n",
      "meta-llama/llama-3-70b-instruct\n",
      "mistralai/mixtral-8x22b-instruct\n",
      "microsoft/wizardlm-2-8x22b\n",
      "microsoft/wizardlm-2-7b\n",
      "google/gemini-pro-1.5\n",
      "openai/gpt-4-turbo\n",
      "cohere/command-r-plus\n",
      "cohere/command-r-plus-04-2024\n",
      "databricks/dbrx-instruct\n",
      "sophosympatheia/midnight-rose-70b\n",
      "cohere/command\n",
      "cohere/command-r\n",
      "anthropic/claude-3-haiku:beta\n",
      "anthropic/claude-3-haiku\n",
      "anthropic/claude-3-opus:beta\n",
      "anthropic/claude-3-opus\n",
      "anthropic/claude-3-sonnet:beta\n",
      "anthropic/claude-3-sonnet\n",
      "cohere/command-r-03-2024\n",
      "mistralai/mistral-large\n",
      "google/gemma-7b-it\n",
      "openai/gpt-3.5-turbo-0613\n",
      "openai/gpt-4-turbo-preview\n",
      "nousresearch/nous-hermes-2-mixtral-8x7b-dpo\n",
      "mistralai/mistral-small\n",
      "mistralai/mistral-tiny\n",
      "mistralai/mistral-medium\n",
      "cognitivecomputations/dolphin-mixtral-8x7b\n",
      "google/gemini-pro-vision\n",
      "google/gemini-pro\n",
      "mistralai/mixtral-8x7b\n",
      "mistralai/mixtral-8x7b-instruct\n",
      "openchat/openchat-7b:free\n",
      "openchat/openchat-7b\n",
      "neversleep/noromaid-20b\n",
      "anthropic/claude-2:beta\n",
      "anthropic/claude-2\n",
      "anthropic/claude-2.1:beta\n",
      "anthropic/claude-2.1\n",
      "teknium/openhermes-2.5-mistral-7b\n",
      "undi95/toppy-m-7b:free\n",
      "undi95/toppy-m-7b\n",
      "alpindale/goliath-120b\n",
      "openrouter/auto\n",
      "openai/gpt-3.5-turbo-1106\n",
      "openai/gpt-4-1106-preview\n",
      "google/palm-2-chat-bison-32k\n",
      "google/palm-2-codechat-bison-32k\n",
      "jondurbin/airoboros-l2-70b\n",
      "xwin-lm/xwin-lm-70b\n",
      "openai/gpt-3.5-turbo-instruct\n",
      "mistralai/mistral-7b-instruct-v0.1\n",
      "pygmalionai/mythalion-13b\n",
      "openai/gpt-3.5-turbo-16k\n",
      "openai/gpt-4-32k\n",
      "openai/gpt-4-32k-0314\n",
      "nousresearch/nous-hermes-llama2-13b\n",
      "mancer/weaver\n",
      "huggingfaceh4/zephyr-7b-beta:free\n",
      "anthropic/claude-2.0:beta\n",
      "anthropic/claude-2.0\n",
      "undi95/remm-slerp-l2-13b\n",
      "google/palm-2-chat-bison\n",
      "google/palm-2-codechat-bison\n",
      "gryphe/mythomax-l2-13b:free\n",
      "gryphe/mythomax-l2-13b\n",
      "meta-llama/llama-2-13b-chat\n",
      "meta-llama/llama-2-70b-chat\n",
      "openai/gpt-3.5-turbo\n",
      "openai/gpt-3.5-turbo-0125\n",
      "openai/gpt-4\n",
      "openai/gpt-4-0314\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# Liste les modèles disponibles\n",
    "models = openai.Model.list()\n",
    "\n",
    "# Afficher les modèles disponibles\n",
    "for model in models[\"data\"]:\n",
    "    print(model[\"id\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mon IA avec OpenRouter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oui, l'attieke est un plat ivoirien à base de semoule de manioc fermentée. Il est généralement servi avec une sauce ou un accompagnement tel que du poisson, de la viande ou des légumes. C'est un plat très populaire en Côte d'Ivoire.\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "openai.api_base = \"https://openrouter.ai/api/v1\"\n",
    "def generate_response_openrouter( prompt ) :\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"openai/gpt-3.5-turbo\",\n",
    "        messages =[{\"role\": \"user\", \"content\": prompt } ]\n",
    "    )\n",
    "    return response [\"choices\"] [0] [\"message\"] [\"content\"]\n",
    "User_prompt = input(\"Entrez votre question: \")\n",
    "print(generate_response_openrouter(User_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TP3 COHERE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oui, je connais l'attiéké ! L'attiéké est un plat traditionnel ivoirien fait à base de manioc fermenté et râpé. C'est un accompagnement populaire en Côte d'Ivoire et dans d\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "co = cohere.Client(\"dswOxdG69W3ooIlUYaqN4DTTAF2XWWgBZe0juDtx\")\n",
    "def generate_response_cohere (prompt):\n",
    "    response = co.generate(\n",
    "        model=\"command-r-plus\",\n",
    "        prompt=prompt ,\n",
    "        max_tokens=50\n",
    "    )\n",
    "    return response.generations[0].text\n",
    "User_prompt= input()\n",
    "print(generate_response_cohere(User_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johan/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/chat-bison-001\n",
      "models/text-bison-001\n",
      "models/embedding-gecko-001\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-pro-vision\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-1.5-pro-001\n",
      "models/gemini-1.5-pro-002\n",
      "models/gemini-1.5-pro\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-flash-001\n",
      "models/gemini-1.5-flash-001-tuning\n",
      "models/gemini-1.5-flash\n",
      "models/gemini-1.5-flash-002\n",
      "models/gemini-1.5-flash-8b\n",
      "models/gemini-1.5-flash-8b-001\n",
      "models/gemini-1.5-flash-8b-latest\n",
      "models/gemini-1.5-flash-8b-exp-0827\n",
      "models/gemini-1.5-flash-8b-exp-0924\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/learnlm-1.5-pro-experimental\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n"
     ]
    }
   ],
   "source": [
    "#chercher la liste des modèles disponibles\n",
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"GOOGLE_API_KEY2\")\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "models = genai.list_models()\n",
    "for model in models:\n",
    "    print(model.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
